\subsection{Simple generative model: no latent variable}

\subsubsection{Context and objective}

In first approximation, we would like to define a generative model that does not exploit any latent structure.
Such model, parameterized by $\theta$, aims at finding an optimal distribution in the sense of the maximum of likelihood,
within a family of distributions yet to be defined.
The maximum likelihood objective is given below as:
$$
\theta^* = arg\max_{\theta} p_{\theta}(X, T)
$$
One can rewrite the joint distribution as follow:
$$
\begin{align}
    p_{\theta}(X, T) &= \prod_{i=1}^n p_{\theta}(X_i, T_i) \\
                    &= \prod_{i=1}^n p_{\theta}(T_i) p_{\theta}(X_i | T_i)
\end{align}
$$

As a result, to compute this objective, we need to define a prior $p_{\theta}(T_i)$ that generates trees,
and a posterior distribution $p_{\theta}(X_i | T_i)$ that generates abundance data from a sampled tree. \\

Note that in this section we assume that the trees do not have missing entries, meaning all the branches of
reach the maximum precision layer of the tree, so that the abundance data sum to $1$ at each level. \\

% Design of the prior and optimization
\input{sections/microbiota_analysis/tree_generation_prior/markovian_parenting_nodes_prior.tex}

\subsubsection{Design of the posterior and maximum likelihood estimator}

% Design of the posterior

Now that we have a way to generate trees, we need to define an explicit stochastic relationship between the abundance
data and the structure of the tree.
Such inevitably exists, as when observing $T$, the abundance of an entity that isn't present in $T$ is necessarily 0.
Similarly, it is highly likely that when observing the presence of certain entities in $T$ that induces a high abundance of
another neighbour entity (interaction between bacteria). \\

For context, we recall that $X$ is a matrix of shape $(D, U)$.
We denote by $X^{(l)}$ the $l$-th line of the abundance matrix, for which up to $U_l$ elements should be non-zero. \\

Since we would like an explicit model here, we design a posterior $p_{\theta}(X|T)$ which is markovian relatively to the layers of the tree:
$$
p_{\theta}(X^{(l)} | X^{(1:l-1)}, T) = p_{\theta}(X^{(l)} | X^{(l-1)}, T)
$$
We assume the following framework:
\begin{itemize}
    \item We denote $X^{(l)} = (x_l^{(1)}, \dots, x_{l}^{(U)})$ the abundance vector at layer $l$.
    \item $X^{(1)} = [1, 0, \dots, 0]$, since it's the root of the tree, only one entity gets the whole weight.
    \item We assume that for all $l \geq 2, X^{(l)} | T \sim \mathcal{D}(\alpha_l)$.
    \item Each value in $X^{(l)}$ is restricted by the following set of constraints:
        \begin{itemize}
              \item If node $k$ at layer $l-1$ has one child, then its abundance value is the same for the child node.
              \item If node $k$ at layer $l-1$ has at least two children, the children abundance sums to the parent's abundance value.
        \end{itemize}
        We denote by $\mathcal{C}_T$ the set of vectors that verify the previous constraints for the tree $T$.
        Hence, we obtain the following conditional distribution:
        $$
        \begin{align}
            p_{\gamma_l}(X^{(l+1)} | X^{(l)}, T) &= \frac{p_{\gamma'_l}(X^{(l+1)}, X^{(l)}, T)}{p_{\alpha_l}(X^{(l)}, T)} \\
                                            &= \frac{p_{\alpha_{l+1}}(X^{(l+1)} | T)}{p_{\alpha_{l}}(X^{(l)} | T)} p(X^{(l)} | X^{(l+1)}, T) \\
                                            &= \frac{p_{\alpha_{l+1}}(X^{(l+1)} | T)}{p_{\alpha_{l}}(X^{(l)} | T)} \mathds{1}_{\mathcal{C}_T}\left(X^{(l)}, X^{(l+1)}\right)
        \end{align}
        $$
\end{itemize}

The whole posterior is then given by:
$$
\begin{align}
    p_{\theta}(X | T) &= \prod_{i=1}^n p_{\theta}(X_i | T_i) \\
                    &= \prod_{i=1}^n p_{\theta}(X_i^{(1)}, \dots, X_i^{(D)} | T_i) \\
                    &= \prod_{i=1}^n p(X_i^{(1)} | T_i) \prod_{l=1}^{D-1} p_{\gamma_j}(X_i^{(l+1)} | X_i^{(l)}, T_i) \\
                    &= \prod_{i=1}^n \mathds{1}_{X_i^{(1)} = e_1} \prod_{l=1}^{D-1} \frac{p_{\alpha_{l+1}}(X_i^{(l+1)} | T_i)}{p_{\alpha_{l}}(X_i^{(l)} | T_i)} \mathds{1}_{\mathcal{C}_{T_i}}\left(X_i^{(l)}, X_i^{(l+1)}\right) \\
                    &= \prod_{i=1}^n p_{\alpha_{D}}(X_i^{(D)} | T_i) \mathds{1}_{X_i^{(1)} = e_1} \prod_{l=1}^{D-1} \mathds{1}_{C_{T_i}}(X_i^{(l)} X_i^{(l+1)})
\end{align}
$$

Hence, to generate an abundance matrix $X$ out of a tree $T$, we just need to sample the highest precision layer of the tree
and roll it up to the top thanks to the tree structure that we observe.
As a result, this posterior is only characterized by one parameter $\alpha_D$ that is the dirichlet parameter of the ultimate layer of the tree. Sampling from the last layer $D$ has to be made explicit though.
We assume that the abundance at the last layer only depends on the last layer of the tree, so that:
$$
p_{\alpha_D}(X_i^{(D)} | T_i) = p_{\alpha_D}(X_i^{(D)} | T_i^{(D)})
$$
\newcommand{\nodeindexset}{\mathcal{L}^{(D)}_{T_i}}
Knowing the last layer structure $T_i^{(D)}$ enables us to tell for sure where some $0$ abundances are going to be.
Recall $\nodeindexset$, the set of indexes so that the node associated to that index belongs to any branch at the level set $T_i^{(D)}$ in $T_i$:
$$
\nodeindexset = \left\{k \in \{1, \dots, U\} | u_k^{(D)} \in T_i^{(D)}\right\}
$$
We can now describe the last layer's abundance conditionally to the tree:
$$
\begin{align}
    p(X_i^{(D)} | T_i) &= p(X_i^{(D)} | T_i^{(D)}) \\
                                &= p\left(\left[X_i^{(D)}\right]_1, \dots, \left[X_i^{(D)}\right]_U | \bigcap_{k' \notin \nodeindexset} \left[X_i^{(D)}\right]_{k'} = 0\right) \\
                                &= \frac{p_{\alpha_D}\left( \bigcap_{k \in \nodeindexset} \left[X_i^{(D)}\right]_{k}, \bigcap_{k' \notin \nodeindexset} \left[X_i^{(D)}\right]_{k'} = 0 \right)}{\int p_{\alpha_D}\left( \bigcap_{k \in \nodeindexset} \left[\tilde{X}_i^{(D)}\right]_{k}, \bigcap_{k' \notin \nodeindexset} \left[X_i^{(D)}\right]_{k'} = 0 \right) d\tilde{X}} \\
                                &= \frac{\frac{1}{B(\alpha_D)} \prod_{k \in \nodeindexset} \left[X_i^{(D)}\right]_{k}^{\alpha_D^{(k)} - 1} \prod_{k' \notin \nodeindexset} \left[X_i^{(D)}\right]_{k'}^{\alpha_D^{(k')} - 1}}{\frac{1}{B(\alpha_D)} \prod_{k' \notin \nodeindexset} \left[X_i^{(D)}\right]_{k'}^{\alpha_D^{(k')} - 1} \prod_{k \in \nodeindexset} \int_{0}^{1} \left[\tilde{X}_i^{(D)}\right]_k^{\alpha_D^{(k)} - 1} d\left[\tilde{X}_i^{(D)}\right]_k} \\
                                &= \prod_{k \in \nodeindexset} \alpha_D^{(k)} \left[X_i^{(D)}\right]_k^{\alpha_D^{(k)} - 1}
\end{align}
$$
Plugin that result into the whole distribution, we obtain that final formulation of the posterior distribution:
$$
    p_{\theta}(X | T) = \prod_{i=1}^n \prod_{k \in \nodeindexset} \alpha_D^{(k)} \left[X_i^{(D)}\right]_k^{\alpha_D^{(k)} - 1} \mathds{1}_{X_i^{(1)} = e_1} \prod_{l=1}^{D-1} \mathds{1}_{C_{T_i}}(X_i^{(l)}, X_i^{(l+1)})
$$

% Optimization of the posterior

Now that we have described the posterior distribution, we would like to compute an optimal parameter for such distributions under a maximum likelihood objective, that is given by $\alpha_D^* = (\alpha_D^{(1)}, \dots, \alpha_D^{(U)})$.
The optimization objective for each component is the following:
$$
(\alpha_D^{(j)})^* = arg \max_{\alpha_D^{(k)}} \sum_{i=1}^n \log p_{\alpha_D}(X_i^{(D)}|T_i) + \log \mathds{1}_{X_i^{(1)} = e_1} + \sum_{k=1}^{D-1} \log \mathds{1}_{C_{T_i}}(X_i^{(l)}, X_i^{(l+1)})
$$

Since the indicator function do not depend on the parameter, we only have to solve the following problem:
$$
(\alpha_D^{(j)})^* = arg \max_{\alpha_D^{(k)}} \sum_{i=1}^n \sum_{k \in \nodeindexset} \log \alpha_D^{(k)} + \left(\alpha_D^{(k)} - 1\right) \log \left[X_i^{(D)} \right]_k
$$
Deriving with respect to $\alpha_D^{(j)}$, if any tree has the node $j$, we get:
$$
\fbox{

    \displaystyle (\alpha_D^{(j)})^* = \frac{\sum_{i=1}^n \mathds{1}_{j \in \nodeindexset}}{\sum_{i=1}^n \mathds{1}_{j \in \nodeindexset} \log \frac{1}{\left[X_i^{(D)} \right]_j}\right}

}

\subsubsection{Optimization of the objective}

Recall the optimization objective, written under the maximum of the log-likelihood:
$$
\begin{align}
    \theta^* &= arg \max_{\theta} \log p_{\theta}(X,T) \\
            &= arg \max_{\theta} \sum_{i=1}^n \log p_{\theta}(X_i, T_i) \\
            &= arg \max_{\theta} \sum_{i=1}^n \log p_{\theta}(T_i) + \log p_{\theta}(X_i | T_i)
\end{align}
$$

Notice that the first term of the loss is made only of the prior, while the second one is made only of the posterior.
Since these two distributions do not share common parameters in $\theta$, we can proceed to optimize the parameters of each distribution
without taking care of the other term. \\

Hence, the optimal $\theta^*$ is given by the concatenation of the MLE from the prior on the trees and the posterior of the abundance knowning the trees,
which we both have computed in the previous sections.

%Since the indicator functions do not depend on the parameter, we end up on a known problem of maximum of likelihood for Dirichlet distribution \cite{dirichlet_digamma_trick}.
%As we have done the maths in another context for the dirichlet mixture, we get a similar result that ends up on the following fixed point algorithm:
%$$
%\fbox{
%    \displaystyle\left(\alpha_D^{(j)}\right)^{(m+1)} = \psi^{-1}\left(\frac{1}{n} \sum_{i=1}^n \log \left[X_i^{(D)}\right]_j + \psi \left(\sum_{r=1}^U \left(\alpha_{D}^{(r)}\right)^{(m)}\right) \right)
%}
%$$

\subsubsection{Experiments}

We have implemented the previous modelization and tested it on a large microbiota dataset.

\subsubsection{Conclusions}

This first model is interesting as it provides a benchmark baseline for our upcoming tree-structured models.
However, it clearly lacks of complexity:
\begin{itemize}
    \item The nodes are modeled as independent, which prevents any modelisation of correlation between entities.
          As for many ecosystems, we would expect some bacteria to have symbiotic relationship, or domination roles,
          especially when we come in critical systems like disease detection in which some bacteria may proliferate over others.
          One idea could be to model an interaction graph (see \cite{momal_tree}) and use it as a correlation restriction between our bacteria.
    \item The abundance data generation takes the tree constraints into account, yet it is poorly flexible as we sample from a unique Dirichlet
          parameterized by $\alpha_D$ and masked according to $T^{(D)}$, which completely omits the tree's global structure.
          It would be highly interesting to try to group the trees through a latent variable for instance, and adapt the parameter
          to that specific group to enhance the modelization.
          We will explore that situation in the next section.
    \item So far we have only considered trees without any missing entries at precision level $L$, which is not what we observe for microbiota datasets.
          Inference for missing data implementation could be interesting in the future.
\end{itemize}